{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "200cd96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 Python 路径: d:\\anaconda3\\envs\\learning_venv\\python.exe\n",
      "PyTorch 版本: 2.5.1\n",
      "CUDA 是否可用: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"当前 Python 路径:\", sys.executable)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch 版本:\", torch.__version__)\n",
    "    print(\"CUDA 是否可用:\", torch.cuda.is_available())\n",
    "except ImportError:\n",
    "    print(\"尚未安装 PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d09fec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\learning_venv\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import SimpleCNN\n",
    "torch.manual_seed(42)\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "epochs = 5\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70f587c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "244ef7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss = 1018.9002\n",
      "Epoch [2/5], Loss = 720.2967\n",
      "Epoch [3/5], Loss = 592.6648\n",
      "Epoch [4/5], Loss = 483.8115\n",
      "Epoch [5/5], Loss = 382.8980\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss = {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.92%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "#final accuracy: 71.92%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29c948a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std =[0.2470, 0.2435, 0.2616])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss = 1.8899\n",
      "Epoch [2/100], Loss = 1.3298\n",
      "Epoch [3/100], Loss = 1.1517\n",
      "Epoch [4/100], Loss = 1.0282\n",
      "Epoch [5/100], Loss = 0.9350\n",
      "Epoch [6/100], Loss = 0.8851\n",
      "Epoch [7/100], Loss = 0.8463\n",
      "Epoch [8/100], Loss = 0.8082\n",
      "Epoch [9/100], Loss = 0.7907\n",
      "Epoch [10/100], Loss = 0.7702\n",
      "Epoch [11/100], Loss = 0.7554\n",
      "Epoch [12/100], Loss = 0.7419\n",
      "Epoch [13/100], Loss = 0.7251\n",
      "Epoch [14/100], Loss = 0.7139\n",
      "Epoch [15/100], Loss = 0.7030\n",
      "Epoch [16/100], Loss = 0.6921\n",
      "Epoch [17/100], Loss = 0.6895\n",
      "Epoch [18/100], Loss = 0.6814\n",
      "Epoch [19/100], Loss = 0.6832\n",
      "Epoch [20/100], Loss = 0.6737\n",
      "Epoch [21/100], Loss = 0.6707\n",
      "Epoch [22/100], Loss = 0.6752\n",
      "Epoch [23/100], Loss = 0.6709\n",
      "Epoch [24/100], Loss = 0.6599\n",
      "Epoch [25/100], Loss = 0.6621\n",
      "Epoch [26/100], Loss = 0.6612\n",
      "Epoch [27/100], Loss = 0.6588\n",
      "Epoch [28/100], Loss = 0.6546\n",
      "Epoch [29/100], Loss = 0.6574\n",
      "Epoch [30/100], Loss = 0.6483\n",
      "Epoch [31/100], Loss = 0.6477\n",
      "Epoch [32/100], Loss = 0.6462\n",
      "Epoch [33/100], Loss = 0.6439\n",
      "Epoch [34/100], Loss = 0.6484\n",
      "Epoch [35/100], Loss = 0.6456\n",
      "Epoch [36/100], Loss = 0.6461\n",
      "Epoch [37/100], Loss = 0.6431\n",
      "Epoch [38/100], Loss = 0.6363\n",
      "Epoch [39/100], Loss = 0.6379\n",
      "Epoch [40/100], Loss = 0.6399\n",
      "Epoch [41/100], Loss = 0.6355\n",
      "Epoch [42/100], Loss = 0.6356\n",
      "Epoch [43/100], Loss = 0.6327\n",
      "Epoch [44/100], Loss = 0.6351\n",
      "Epoch [45/100], Loss = 0.6274\n",
      "Epoch [46/100], Loss = 0.6316\n",
      "Epoch [47/100], Loss = 0.6338\n",
      "Epoch [48/100], Loss = 0.6254\n",
      "Epoch [49/100], Loss = 0.6276\n",
      "Epoch [50/100], Loss = 0.6249\n",
      "Epoch [51/100], Loss = 0.6250\n",
      "Epoch [52/100], Loss = 0.6297\n",
      "Epoch [53/100], Loss = 0.6249\n",
      "Epoch [54/100], Loss = 0.6251\n",
      "Epoch [55/100], Loss = 0.6224\n",
      "Epoch [56/100], Loss = 0.6212\n",
      "Epoch [57/100], Loss = 0.6256\n",
      "Epoch [58/100], Loss = 0.6240\n",
      "Epoch [59/100], Loss = 0.6207\n",
      "Epoch [60/100], Loss = 0.6226\n",
      "Epoch [61/100], Loss = 0.2953\n",
      "Epoch [62/100], Loss = 0.1778\n",
      "Epoch [63/100], Loss = 0.1363\n",
      "Epoch [64/100], Loss = 0.1304\n",
      "Epoch [65/100], Loss = 0.1500\n",
      "Epoch [66/100], Loss = 0.1460\n",
      "Epoch [67/100], Loss = 0.1495\n",
      "Epoch [68/100], Loss = 0.1564\n",
      "Epoch [69/100], Loss = 0.1475\n",
      "Epoch [70/100], Loss = 0.1499\n",
      "Epoch [71/100], Loss = 0.1571\n",
      "Epoch [72/100], Loss = 0.1509\n",
      "Epoch [73/100], Loss = 0.1411\n",
      "Epoch [74/100], Loss = 0.1422\n",
      "Epoch [75/100], Loss = 0.1465\n",
      "Epoch [76/100], Loss = 0.1395\n",
      "Epoch [77/100], Loss = 0.1510\n",
      "Epoch [78/100], Loss = 0.1355\n",
      "Epoch [79/100], Loss = 0.1433\n",
      "Epoch [80/100], Loss = 0.1462\n",
      "Epoch [81/100], Loss = 0.1384\n",
      "Epoch [82/100], Loss = 0.1406\n",
      "Epoch [83/100], Loss = 0.1333\n",
      "Epoch [84/100], Loss = 0.1291\n",
      "Epoch [85/100], Loss = 0.1393\n",
      "Epoch [86/100], Loss = 0.1302\n",
      "Epoch [87/100], Loss = 0.1415\n",
      "Epoch [88/100], Loss = 0.1436\n",
      "Epoch [89/100], Loss = 0.1342\n",
      "Epoch [90/100], Loss = 0.1351\n",
      "Epoch [91/100], Loss = 0.1300\n",
      "Epoch [92/100], Loss = 0.1365\n",
      "Epoch [93/100], Loss = 0.1458\n",
      "Epoch [94/100], Loss = 0.1365\n",
      "Epoch [95/100], Loss = 0.1339\n",
      "Epoch [96/100], Loss = 0.1246\n",
      "Epoch [97/100], Loss = 0.1422\n",
      "Epoch [98/100], Loss = 0.1343\n",
      "Epoch [99/100], Loss = 0.1282\n",
      "Epoch [100/100], Loss = 0.1295\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "epochs = 100\n",
    "model = resnet18(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,momentum=0.9,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[60, 120, 160],\n",
    "    gamma=0.2\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss = {avg_loss:.4f}\")\n",
    "#loss\n",
    "#Epoch [99/100], Loss = 0.1282\n",
    "#Epoch [100/100], Loss = 0.1295\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.42%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "# final accuracy: 77.42%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
